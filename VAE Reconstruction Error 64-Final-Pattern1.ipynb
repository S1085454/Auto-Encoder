{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tb=SummaryWriter()\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 256\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Training/Normal\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "train_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Training/Normal', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=False)\n",
    "len(train_dataset.imgs), len(train_dataloader)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_x, _ = next(iter(train_dataloader))\n",
    "# save_image(fixed_x, 'VAE_CLAHE_Training.png')\n",
    "\n",
    "# Image('VAE_CLAHE_Training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=1024, z_dim=64):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(1024, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_channels = fixed_x.size(1)\n",
    "image_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Flatten()\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1024, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU()\n",
       "    (16): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (20): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE(image_channels=image_channels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "#     BCE = F.binary_cross_entropy(recon_x, x, size_average=False).to(device)\n",
    "    MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()).to(device)\n",
    "    return MSE + KLD, MSE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 3, 128, 128)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/N/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/N/', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_test, _ = next(iter(test_dataloader))\n",
    "# save_image(fixed_test, 'xxx.png')\n",
    "\n",
    "# Image('xxx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(test_dataloader)\n",
    "for i in range(len(test_dataloader)):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "        save_image(data, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Original_VAE_latent64_{}.png'.format(i))\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(dataloader)\n",
    "        data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Flatten()\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1024, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU()\n",
       "    (16): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (20): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= VAE(image_channels=image_channels)\n",
    "test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Flatten()\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1024, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU()\n",
       "    (16): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (20): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.load_state_dict(torch.load('./autoencoder_VAE_latent64_Thesis_Pattern1.pth'))\n",
    "test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=-1\n",
    "for idx, (images, _) in enumerate(test_dataloader):\n",
    "    images, _=images.cuda(), _.cuda()\n",
    "    recon_images, mu, logvar = test(images)\n",
    "    loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "    pic = to_img(recon_images.cpu().data)\n",
    "    b=b+1\n",
    "    save_image(pic, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Reconstructed_Normal_VAE_latent64_{}.png'.format(b))\n",
    "#     print('loss:{:.4f}'.format(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/N/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 1\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/N/', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_test, _ = next(iter(test_dataloader))\n",
    "# save_image(fixed_test, 'xxx.png')\n",
    "\n",
    "# Image('xxx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.8491, 77.1413, 75.3286, 17.2044, 15.0334, 20.3347, 17.5572, 17.4297, 20.083, 19.3995, 18.1543, 81.4189, 79.2332, 18.8133, 71.541, 18.1932, 20.2143, 21.2451, 19.3407, 13.228, 18.4447, 14.8377, 13.6319, 15.1786, 17.082, 10.1755, 12.2737, 14.8983, 15.8664, 16.9394, 19.7474, 73.941, 16.1861, 26.1337, 20.6428, 20.0689, 22.2314, 18.5795, 87.4217, 91.4237, 72.0904, 71.2395, 81.5008, 94.5164, 102.1982, 125.9195, 15.9733, 16.7832, 15.3908, 18.0892, 16.186, 14.1012, 15.9085, 16.5495, 20.8201, 22.4088, 25.4558, 34.617, 59.3532, 39.2752, 91.7926, 30.756, 34.3481, 61.1353, 51.1695, 44.2684, 123.8496, 53.6164, 20.5175, 22.1885, 36.207, 64.9779, 130.9507, 101.68, 151.9765, 122.8367, 126.9604, 168.1967, 143.2027, 141.6596, 83.0098, 72.9478, 69.7442, 78.4675, 90.8466, 95.6865, 124.4812, 12.5025, 12.0596, 8.6646, 9.2384, 12.3093, 11.9592, 12.3277, 17.0029, 88.2335, 10.3854, 9.4816, 18.0457, 98.2792, 12.0842, 10.3696, 10.8427, 9.9182, 9.5914, 12.646, 78.5984, 80.4492, 15.7467, 19.1806, 82.2455, 22.938, 76.7249, 97.8096, 103.5784, 95.8553, 83.3136, 80.6131, 73.7974, 96.522, 89.6621, 82.0859, 68.7871, 14.6377, 14.4771, 12.8619, 16.018, 12.6208]\n"
     ]
    }
   ],
   "source": [
    "loss_append=[]\n",
    "for idx, (images, _) in enumerate(test_dataloader):\n",
    "    images, _=images.cuda(), _.cuda()\n",
    "    recon_images, mu, logvar = test(images)\n",
    "    loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "#     print('{:.4f}'.format(loss.data))\n",
    "    loss = round(float(loss.data),4)\n",
    "    loss_append.append(loss)\n",
    "\n",
    "print(loss_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/A/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/A/', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_test, _ = next(iter(test_dataloader))\n",
    "# save_image(fixed_test, 'xxx.png')\n",
    "\n",
    "# Image('xxx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(test_dataloader)\n",
    "for i in range(len(test_dataloader)):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "        save_image(data, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Abnormal_VAE_latent64_{}.png'.format(i))\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(dataloader)\n",
    "        data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=-1\n",
    "for idx, (images, _) in enumerate(test_dataloader):\n",
    "    images, _=images.cuda(), _.cuda()\n",
    "    recon_images, mu, logvar = test(images)\n",
    "    loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "    pic = to_img(recon_images.cpu().data)\n",
    "    b=b+1\n",
    "    save_image(pic, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Reconstructed_Abnormal_VAE_latent64_{}.png'.format(b))\n",
    "#     print('loss:{:.4f}'.format(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/A/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 1\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/A/', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_test, _ = next(iter(test_dataloader))\n",
    "# save_image(fixed_test, 'xxx.png')\n",
    "\n",
    "# Image('xxx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209.3277, 169.9041, 227.5607, 141.8554, 303.6899, 271.8334, 213.589, 90.7801, 211.1326, 174.3153, 168.4976, 152.004, 180.2031, 156.0409, 118.792, 170.6975, 1031.7002, 412.3208, 452.2428, 641.0493, 1395.7559, 425.3205, 716.5728, 380.0307, 85.6064, 501.28, 5.77607560111063e+16, 1803671650172928.0, 4.144746519855104e+17, 6.817256944887631e+21, 35500224151552.0, 9461670346752.0, 5059283779584.0, 241773104332800.0, 1581084180480.0, 72888288.0, 216300240.0, 36185411584.0, 2622529847951360.0, 5.398131363964518e+16, 2325566193664.0, 129591040.0, 519.9814, 646.563, 499.1664, 129.6111, 168.4323, 88.8074, 60.5398, 108.248, 137.9653, 123.2534, 67.687, 147.5929, 124.6011, 169.188, 191.1688, 378.5792, 271.6268, 188.7611, 136.0882, 204.3412, 167.2565, 42.7295, 44283.9727, 187924.4844, 2021296570368.0, 1443279.25, 4214270464.0, 12249.0176, 37791.7852, 3718.9971, 399.0495, 376.5633, 719.7583, 1189.6281, 1131.5093, 2805.0356, 2297.2886, 412.6993, 9.589618120912783e+27, 1182.9854, 82256896.0, 1259.8999, 1122643.625, 1701.6562, 963761.4375, 22964.5254, 59641.9062, 13672.8193, 96456.4297, 17429.2266, 91958.625, 9602.6953, 70477.6094, 422.8808, 4716.8711, 350.3986, 33.7337, 345.6615, 25831.6582, 30128.0879, 203506.625, 220.2318, 1603.5657, 108013838336.0, 2369493460320256.0, 1304036359798784.0, 79519940608.0, 3.5639601568666144e+21, 282131648.0, 2715965787734016.0, 661956224.0, 723.6603, 758.6626, 37580.6367, 954.5754, 576.8735, 2399.1599, 54110.168, 1415.0641, 1354.5753, 1731.4552, 1841.6036, 1974.3734, 2193.3914, 1919.6095, 1027.5156]\n"
     ]
    }
   ],
   "source": [
    "loss_append_ano=[]\n",
    "for idx, (images, _) in enumerate(test_dataloader):\n",
    "    images, _=images.cuda(), _.cuda()\n",
    "    recon_images, mu, logvar = test(images)\n",
    "    loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "#     print('{:.4f}'.format(loss.data))\n",
    "    loss = round(float(loss.data),4)\n",
    "    loss_append_ano.append(loss)\n",
    "print(loss_append_ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.41609499999998"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "percentile=np.percentile(loss_append, 95, axis=0)\n",
    "percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_testing=loss_append\n",
    "normal_testing = np.array_split(normal_testing, len(normal_testing)/32)\n",
    "\n",
    "anomaly_testing=loss_append_ano\n",
    "anomaly_testing = np.array_split(anomaly_testing, len(anomaly_testing)/32)\n",
    "\n",
    "a=np.array(normal_testing).shape\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN= 121 TP= 117\n",
      "FP= 7 FN= 11\n"
     ]
    }
   ],
   "source": [
    "#TP\n",
    "TP=0\n",
    "FN=0\n",
    "for j in range(128):   \n",
    "    if loss_append_ano[j]>percentile:   \n",
    "        TP=TP+1\n",
    "    else:\n",
    "        FN=FN+1\n",
    "\n",
    "TN=0\n",
    "FP=0\n",
    "for j in range(128):   \n",
    "    if loss_append[j]>percentile:   \n",
    "        FP=FP+1\n",
    "    else:\n",
    "        TN=TN+1\n",
    "print (\"TN=\",TN,\"TP=\",TP)\n",
    "print (\"FP=\",FP,\"FN=\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN= 115 TP= 121\n",
      "FP= 13 FN= 7\n"
     ]
    }
   ],
   "source": [
    "percentile=np.percentile(loss_append, 90, axis=0)\n",
    "percentile\n",
    "#TP\n",
    "TP=0\n",
    "FN=0\n",
    "for j in range(128):   \n",
    "    if loss_append_ano[j]>percentile:   \n",
    "        TP=TP+1\n",
    "    else:\n",
    "        FN=FN+1\n",
    "\n",
    "TN=0\n",
    "FP=0\n",
    "for j in range(128):   \n",
    "    if loss_append[j]>percentile:   \n",
    "        FP=FP+1\n",
    "    else:\n",
    "        TN=TN+1\n",
    "print (\"TN=\",TN,\"TP=\",TP)\n",
    "print (\"FP=\",FP,\"FN=\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_testing=loss_append\n",
    "normal_testing = np.array_split(normal_testing, len(normal_testing)/32)\n",
    "\n",
    "anomaly_testing=loss_append_ano\n",
    "anomaly_testing = np.array_split(anomaly_testing, len(anomaly_testing)/32)\n",
    "\n",
    "a=np.array(normal_testing).shape\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Testing:\n",
      "\n",
      "Normal Batch1\n",
      "15.8491 77.1413 75.3286 17.2044 15.0334 20.3347 17.5572 17.4297\n",
      "20.083 19.3995 18.1543 81.4189 79.2332 18.8133 71.541 18.1932\n",
      "20.2143 21.2451 19.3407 13.228 18.4447 14.8377 13.6319 15.1786\n",
      "17.082 10.1755 12.2737 14.8983 15.8664 16.9394 19.7474 73.941\n",
      "\n",
      "Normal Batch2\n",
      "16.1861 26.1337 20.6428 20.0689 22.2314 18.5795 87.4217 91.4237\n",
      "72.0904 71.2395 81.5008 94.5164 102.1982 125.9195 15.9733 16.7832\n",
      "15.3908 18.0892 16.186 14.1012 15.9085 16.5495 20.8201 22.4088\n",
      "25.4558 34.617 59.3532 39.2752 91.7926 30.756 34.3481 61.1353\n",
      "\n",
      "Normal Batch3\n",
      "51.1695 44.2684 123.8496 53.6164 20.5175 22.1885 36.207 64.9779\n",
      "130.9507 101.68 151.9765 122.8367 126.9604 168.1967 143.2027 141.6596\n",
      "83.0098 72.9478 69.7442 78.4675 90.8466 95.6865 124.4812 12.5025\n",
      "12.0596 8.6646 9.2384 12.3093 11.9592 12.3277 17.0029 88.2335\n",
      "\n",
      "Normal Batch4\n",
      "10.3854 9.4816 18.0457 98.2792 12.0842 10.3696 10.8427 9.9182\n",
      "9.5914 12.646 78.5984 80.4492 15.7467 19.1806 82.2455 22.938\n",
      "76.7249 97.8096 103.5784 95.8553 83.3136 80.6131 73.7974 96.522\n",
      "89.6621 82.0859 68.7871 14.6377 14.4771 12.8619 16.018 12.6208\n",
      "\n",
      "Anomaly Testing:\n",
      "\n",
      "Anomaly Batch1\n",
      "209.3277 169.9041 227.5607 141.8554 303.6899 271.8334 213.589 90.7801\n",
      "211.1326 174.3153 168.4976 152.004 180.2031 156.0409 118.792 170.6975\n",
      "1031.7002 412.3208 452.2428 641.0493 1395.7559 425.3205 716.5728 380.0307\n",
      "85.6064 501.28 5.77607560111063e+16 1803671650172928.0 4.144746519855104e+17 6.817256944887631e+21 35500224151552.0 9461670346752.0\n",
      "\n",
      "Anomaly Batch2\n",
      "5059283779584.0 241773104332800.0 1581084180480.0 72888288.0 216300240.0 36185411584.0 2622529847951360.0 5.398131363964518e+16\n",
      "2325566193664.0 129591040.0 519.9814 646.563 499.1664 129.6111 168.4323 88.8074\n",
      "60.5398 108.248 137.9653 123.2534 67.687 147.5929 124.6011 169.188\n",
      "191.1688 378.5792 271.6268 188.7611 136.0882 204.3412 167.2565 42.7295\n",
      "\n",
      "Anomaly Batch3\n",
      "44283.9727 187924.4844 2021296570368.0 1443279.25 4214270464.0 12249.0176 37791.7852 3718.9971\n",
      "399.0495 376.5633 719.7583 1189.6281 1131.5093 2805.0356 2297.2886 412.6993\n",
      "9.589618120912783e+27 1182.9854 82256896.0 1259.8999 1122643.625 1701.6562 963761.4375 22964.5254\n",
      "59641.9062 13672.8193 96456.4297 17429.2266 91958.625 9602.6953 70477.6094 422.8808\n",
      "\n",
      "Anomaly Batch4\n",
      "4716.8711 350.3986 33.7337 345.6615 25831.6582 30128.0879 203506.625 220.2318\n",
      "1603.5657 108013838336.0 2369493460320256.0 1304036359798784.0 79519940608.0 3.5639601568666144e+21 282131648.0 2715965787734016.0\n",
      "661956224.0 723.6603 758.6626 37580.6367 954.5754 576.8735 2399.1599 54110.168\n",
      "1415.0641 1354.5753 1731.4552 1841.6036 1974.3734 2193.3914 1919.6095 1027.5156\n"
     ]
    }
   ],
   "source": [
    "print(\"Normal Testing:\")\n",
    "for b in range(a[0]):\n",
    "    print('\\nNormal Batch{}'.format(b+1))\n",
    "    for i in range(32):\n",
    "        if (i+1)%8!=0:\n",
    "            print(round(normal_testing[b][i],5),end=\" \")\n",
    "        else:\n",
    "            print(round(normal_testing[b][i],5))\n",
    "\n",
    "print(\"\\nAnomaly Testing:\")\n",
    "for c in range(a[0]):\n",
    "    print('\\nAnomaly Batch{}'.format(c+1))\n",
    "    for z in range(32):\n",
    "        if (z+1)%8!=0:\n",
    "            print(round(anomaly_testing[c][z],5),end=\" \")\n",
    "        else:\n",
    "            print(round(anomaly_testing[c][z],5))\n",
    "b=0\n",
    "c=0\n",
    "i=0\n",
    "z=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
