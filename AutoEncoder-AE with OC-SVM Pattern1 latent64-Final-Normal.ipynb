{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 256\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Training/Normal\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "train_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Training/Normal', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=False)\n",
    "len(train_dataset.imgs), len(train_dataloader)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset_N = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/N', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader_N = torch.utils.data.DataLoader(test_dataset_N, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal_Same']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_N.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset_N_U = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/N_U', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader_N_U = torch.utils.data.DataLoader(test_dataset_N, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal_Unsame']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_N_U.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset_A = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/A', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader_A = torch.utils.data.DataLoader(test_dataset_A, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abnormal']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_A.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_x, _ = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self,i=1024,o=64):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            Flatten(),\n",
    "            nn.Linear(in_features=i, out_features=o),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=o, out_features=i),\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(1024, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= autoencoder()\n",
    "model.load_state_dict(torch.load('./autoencoder_AE_Thesis_Pattern1_latent64.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): ReLU()\n",
       "  (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): ReLU()\n",
       "  (12): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU()\n",
       "  (15): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): ReLU()\n",
       "  (18): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU()\n",
       "  (21): Flatten()\n",
       "  (22): Linear(in_features=1024, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder= model.encoder\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_encode = []\n",
    "for data in train_dataloader:\n",
    "    img, _ = data\n",
    "    img = Variable(img).cuda()\n",
    "    output = encoder(img)\n",
    "    output = output.cpu()\n",
    "    output = output.detach().numpy()\n",
    "    train_normal_encode.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_normal_encode=np.array(train_normal_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.reshape(train_normal_encode, (train_normal_encode.shape[0]*train_normal_encode.shape[1], train_normal_encode.shape[2]))\n",
    "train_normal_encode=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_encode = []\n",
    "for data_normal in test_dataloader_N:\n",
    "    img_normal, _ = data_normal\n",
    "    img_normal = Variable(img_normal).cuda()\n",
    "    output = encoder(img_normal)\n",
    "    output = output.cpu()\n",
    "    output = output.detach().numpy()\n",
    "    test_normal_encode.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_encode=np.array(test_normal_encode)\n",
    "b = np.reshape(test_normal_encode, (test_normal_encode.shape[0]*test_normal_encode.shape[1], test_normal_encode.shape[2]))\n",
    "test_normal_encode=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_encode_N_U = []\n",
    "for data_normal_unsame in test_dataloader_N_U:\n",
    "    img_normal, _ = data_normal\n",
    "    img_normal = Variable(img_normal).cuda()\n",
    "    output = encoder(img_normal)\n",
    "    output = output.cpu()\n",
    "    output = output.detach().numpy()\n",
    "    test_normal_encode_N_U.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_encode_N_U=np.array(test_normal_encode_N_U)\n",
    "b = np.reshape(test_normal_encode_N_U, (test_normal_encode_N_U.shape[0]*test_normal_encode_N_U.shape[1], test_normal_encode_N_U.shape[2]))\n",
    "test_normal_encode_N_U=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_encode = []\n",
    "for data_anomaly in test_dataloader_A:\n",
    "    img_anomaly, _ = data_anomaly\n",
    "    img_anomaly = Variable(img_anomaly).cuda()\n",
    "    output = encoder(img_anomaly)\n",
    "    output = output.cpu()\n",
    "    output = output.detach().numpy()\n",
    "    anomaly_encode.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_encode=np.array(anomaly_encode)\n",
    "b = np.reshape(anomaly_encode, (anomaly_encode.shape[0]*anomaly_encode.shape[1], anomaly_encode.shape[2]))\n",
    "anomaly_encode=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normal_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(train_normal_encode.shape[0]):\n",
    "#     print(anomaly_encode[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scale_train=scaler.fit_transform(train_normal_encode)\n",
    "scale_test=scaler.fit_transform(test_normal_encode)\n",
    "scale_test_unsame=scaler.fit_transform(test_normal_encode_N_U)\n",
    "scale_anomaly=scaler.fit_transform(anomaly_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU: 0.001 Kernel: RBF\n",
      "TN Train: 224 \n",
      "Testing:\n",
      "TN: 86 TP Anomaly: 37 TP Normal Unsame: 44\n",
      "FP: 42 FN Anomaly: 91 FN Normal Unsame: 84 \n",
      "\n",
      "NU: 0.01 Kernel: RBF\n",
      "TN Train: 227 \n",
      "Testing:\n",
      "TN: 86 TP Anomaly: 36 TP Normal Unsame: 44\n",
      "FP: 42 FN Anomaly: 92 FN Normal Unsame: 84 \n",
      "\n",
      "NU: 0.1 Kernel: RBF\n",
      "TN Train: 219 \n",
      "Testing:\n",
      "TN: 86 TP Anomaly: 36 TP Normal Unsame: 44\n",
      "FP: 42 FN Anomaly: 92 FN Normal Unsame: 84 \n",
      "\n",
      "NU: 0.3 Kernel: RBF\n",
      "TN Train: 182 \n",
      "Testing:\n",
      "TN: 79 TP Anomaly: 42 TP Normal Unsame: 52\n",
      "FP: 49 FN Anomaly: 86 FN Normal Unsame: 76 \n",
      "\n",
      "NU: 0.5 Kernel: RBF\n",
      "TN Train: 127 \n",
      "Testing:\n",
      "TN: 48 TP Anomaly: 64 TP Normal Unsame: 64\n",
      "FP: 80 FN Anomaly: 64 FN Normal Unsame: 64 \n",
      "\n",
      "NU: 0.6 Kernel: RBF\n",
      "TN Train: 104 \n",
      "Testing:\n",
      "TN: 41 TP Anomaly: 72 TP Normal Unsame: 76\n",
      "FP: 87 FN Anomaly: 56 FN Normal Unsame: 52 \n",
      "\n",
      "NU: 0.7 Kernel: RBF\n",
      "TN Train: 77 \n",
      "Testing:\n",
      "TN: 30 TP Anomaly: 81 TP Normal Unsame: 88\n",
      "FP: 98 FN Anomaly: 47 FN Normal Unsame: 40 \n",
      "\n",
      "NU: 0.8 Kernel: RBF\n",
      "TN Train: 51 \n",
      "Testing:\n",
      "TN: 20 TP Anomaly: 93 TP Normal Unsame: 100\n",
      "FP: 108 FN Anomaly: 35 FN Normal Unsame: 28 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "nus=[0.001,0.01,0.1,0.3,0.5,0.6,0.7,0.8]\n",
    "for i in range(len(nus)):\n",
    "    clf = svm.OneClassSVM(nu=nus[i], kernel=\"rbf\", gamma='auto')\n",
    "    clf.fit(scale_train)\n",
    "    y_pred_train = clf.predict(scale_train)\n",
    "    y_pred_normal = clf.predict(scale_test)\n",
    "    y_pred_normal_unsame = clf.predict(scale_test_unsame)\n",
    "    y_pred_anomaly = clf.predict(scale_anomaly)\n",
    "    n_true_normal = y_pred_normal[y_pred_normal == 1].size\n",
    "    n_true_normal_unsame = y_pred_normal_unsame[y_pred_normal_unsame == -1].size\n",
    "    n_true_anomaly = y_pred_anomaly[y_pred_anomaly == -1].size\n",
    "    n_true_train = y_pred_train[y_pred_train == 1].size\n",
    "    print('NU:',nus[i],\"Kernel: RBF\")\n",
    "    print('TN Train:',n_true_train,'\\nTesting:')\n",
    "    print('TN:',n_true_normal,'TP Anomaly:',n_true_anomaly,'TP Normal Unsame:',n_true_normal_unsame)\n",
    "    n_error_normal = y_pred_normal[y_pred_normal == -1].size\n",
    "    n_error_normal_unsame = y_pred_normal_unsame[y_pred_normal_unsame == 1].size\n",
    "    n_error_anomaly = y_pred_anomaly[y_pred_anomaly == 1].size\n",
    "    print('FP:',n_error_normal,'FN Anomaly:',n_error_anomaly,'FN Normal Unsame:',n_error_normal_unsame,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
