{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing AE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self,i=1024,o=64):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            Flatten(),\n",
    "            nn.Linear(in_features=i, out_features=o),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=o, out_features=i),\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(1024, 1024, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 3, 128, 128)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "criterion = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Flatten()\n",
       "    (22): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
       "    (1): UnFlatten()\n",
       "    (2): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (18): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (21): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= autoencoder()\n",
    "test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Flatten()\n",
       "    (22): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
       "    (1): UnFlatten()\n",
       "    (2): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (18): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (21): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.load_state_dict(torch.load('./autoencoder_AE_Thesis_Pattern1_latent64.pth'))\n",
    "test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/N\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/N', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(test_dataloader)\n",
    "for i in range(len(test_dataloader)):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "        save_image(data, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Original_AE_latent64_{}.png'.format(i))\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(dataloader)\n",
    "        data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b=-1\n",
    "for data in test_dataloader:\n",
    "    img, _ = data\n",
    "    img = Variable(img).cuda()\n",
    "    # ===================forward=====================\n",
    "    output = test(img)\n",
    "    loss = criterion(output, img)\n",
    "# ===================log========================\n",
    "    pic = to_img(output.cpu().data)\n",
    "    b=b+1\n",
    "    save_image(pic, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Reconstructed_Normal_AE_latent64_{}.png'.format(b))\n",
    "#     print('{:.4f}'.format(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/N\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 1\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/N', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.3114, 17.3876, 15.817, 14.4219, 12.3543, 22.3369, 20.6648, 20.5269, 21.3785, 22.7464, 22.2325, 16.2996, 15.4987, 16.8616, 15.5455, 18.5303, 25.3443, 25.3821, 17.8025, 11.5602, 16.4387, 15.2584, 15.9959, 16.7715, 14.3889, 10.6258, 10.6984, 13.867, 15.4941, 13.2474, 20.6186, 16.1938, 14.6357, 24.135, 21.5189, 18.3244, 20.1778, 18.779, 21.0837, 29.5901, 10.3367, 8.4233, 15.3989, 16.8546, 17.6925, 14.5637, 31.7804, 33.2833, 32.9182, 40.4152, 42.0749, 40.0744, 34.897, 39.109, 48.2419, 52.5372, 63.0014, 63.8946, 71.3912, 98.7255, 76.1255, 83.1536, 92.683, 107.6207, 84.9552, 94.3247, 125.2037, 65.1659, 43.6537, 55.1431, 73.4702, 86.0429, 128.3539, 116.5527, 149.1821, 132.6072, 174.2661, 186.4011, 137.2105, 136.6839, 11.8329, 11.0797, 10.5122, 12.4967, 19.6701, 17.5804, 20.3997, 12.468, 9.2032, 7.0911, 7.7419, 10.6809, 10.9042, 12.0578, 12.8524, 11.3462, 9.7128, 8.9833, 12.1193, 18.5071, 10.8753, 8.728, 10.6808, 9.777, 9.1351, 7.3599, 11.2702, 12.3639, 13.9296, 16.8435, 20.4167, 18.8219, 10.7058, 8.6374, 15.3429, 9.6943, 11.7062, 14.2051, 9.9441, 13.691, 10.3644, 9.2553, 8.4907, 11.464, 15.8648, 13.8325, 14.9932, 14.4916]\n"
     ]
    }
   ],
   "source": [
    "loss_append=[]\n",
    "for data in test_dataloader:\n",
    "    img, _ = data\n",
    "    img = Variable(img).cuda()\n",
    "    # ===================forward=====================\n",
    "    output = test(img)\n",
    "    loss = criterion(output, img)\n",
    "# ===================log========================\n",
    "    pic = to_img(output.cpu().data)\n",
    "    loss = round(float(loss.data),4)\n",
    "#     loss = loss.cpu()\n",
    "#     loss = loss.detach().numpy()\n",
    "    loss_append.append(loss)\n",
    "#     print('{:.4f}'.format(loss.data))\n",
    "#     loss_append.append='{:.4f}'.format(loss)\n",
    "print(loss_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.25132999999997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "percentile=np.percentile(loss_append, 95, axis=0)\n",
    "percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/A\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/A', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(test_dataloader)\n",
    "for i in range(len(test_dataloader)):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "        save_image(data, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Original_Abnormal_AE_latent64_{}.png'.format(i))\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(dataloader)\n",
    "        data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=-1\n",
    "for data in test_dataloader:\n",
    "    img, _ = data\n",
    "    img = Variable(img).cuda()\n",
    "    # ===================forward=====================\n",
    "    output = test(img)\n",
    "    loss = criterion(output, img)\n",
    "# ===================log========================\n",
    "    pic = to_img(output.cpu().data)\n",
    "    b=b+1\n",
    "    save_image(pic, './No_Image_Preprocessing_Pattern1/Test_Reconstructed/Testing_Reconstructed_Abnormal_AE_latent64_{}.png'.format(b))\n",
    "#     print('{:.4f}'.format(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 128\n",
       "    Root location: ./No_Image_Preprocessing_Pattern1/Test/A\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=128, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 1\n",
    "# Load Data\n",
    "test_dataset = datasets.ImageFolder(root='./No_Image_Preprocessing_Pattern1/Test/A', transform=transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "len(test_dataset.imgs), len(test_dataloader)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112.2614, 89.3293, 123.2368, 111.7186, 189.2, 214.5542, 102.2892, 63.0394, 94.9869, 77.7289, 70.8234, 52.5199, 56.5777, 63.6536, 42.9297, 67.2392, 503.1303, 320.2472, 354.2481, 414.6165, 438.2722, 505.069, 327.9466, 286.1786, 25.7157, 248.2355, 10465.3428, 10321.1836, 8645.9795, 8409.1719, 9326.7109, 10761.7549, 13227.8584, 6137.2871, 4474.6812, 3114.7385, 3279.9946, 4472.8267, 8107.9795, 14104.8682, 5287.834, 3942.7998, 334.3032, 280.564, 297.4358, 66.3724, 79.2785, 78.0419, 53.66, 37.7688, 74.6163, 63.6924, 53.3421, 87.2596, 60.5847, 85.823, 105.4669, 176.8144, 67.8948, 82.3275, 31.9626, 75.7112, 41.5004, 39.7015, 2665.2939, 2374.4434, 1040.9232, 2491.7925, 1065.9443, 1685.6021, 1476.9156, 1715.5786, 142.2154, 138.5142, 458.9952, 687.2787, 862.9761, 841.7038, 864.0051, 152.4262, 4663.9375, 1049.4255, 4361.5215, 1175.4775, 3711.2673, 1321.6953, 1066.3696, 2455.8855, 2369.97, 2386.0391, 2215.9375, 2466.5295, 2387.9531, 2315.5498, 2330.7031, 351.7585, 356.4008, 249.9377, 41.1909, 137.2821, 415.3648, 1099.8693, 768.2454, 91.7479, 863.985, 3574.5791, 4601.731, 5104.1699, 3759.2412, 7002.9512, 3587.5247, 7434.6152, 4918.9121, 327.2947, 580.6229, 1161.6997, 310.9071, 239.154, 612.0405, 575.6317, 1149.6494, 1158.3352, 1294.4592, 1273.7156, 1435.4727, 1497.0298, 1475.3424, 828.9168]\n"
     ]
    }
   ],
   "source": [
    "loss_append_ano=[]\n",
    "for data in test_dataloader:\n",
    "    img, _ = data\n",
    "    img = Variable(img).cuda()\n",
    "    # ===================forward=====================\n",
    "    output = test(img)\n",
    "    loss = criterion(output, img)\n",
    "# ===================log========================\n",
    "    pic = to_img(output.cpu().data)\n",
    "    loss = round(float(loss.data),4)\n",
    "#     print('{:.4f}'.format(loss.data))\n",
    "    loss_append_ano.append(loss)\n",
    "print(loss_append_ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN= 121 TP= 93\n",
      "FP= 7 FN= 35\n"
     ]
    }
   ],
   "source": [
    "#TP\n",
    "TP=0\n",
    "FN=0\n",
    "for j in range(128):   \n",
    "    if loss_append_ano[j]>percentile:   \n",
    "        TP=TP+1\n",
    "    else:\n",
    "        FN=FN+1\n",
    "\n",
    "TN=0\n",
    "FP=0\n",
    "for j in range(128):   \n",
    "    if loss_append[j]>percentile:   \n",
    "        FP=FP+1\n",
    "    else:\n",
    "        TN=TN+1\n",
    "print (\"TN=\",TN,\"TP=\",TP)\n",
    "print (\"FP=\",FP,\"FN=\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN= 115 TP= 101\n",
      "FP= 13 FN= 27\n"
     ]
    }
   ],
   "source": [
    "percentile=np.percentile(loss_append, 90, axis=0)\n",
    "percentile\n",
    "#TP\n",
    "TP=0\n",
    "FN=0\n",
    "for j in range(128):   \n",
    "    if loss_append_ano[j]>percentile:   \n",
    "        TP=TP+1\n",
    "    else:\n",
    "        FN=FN+1\n",
    "\n",
    "TN=0\n",
    "FP=0\n",
    "for j in range(128):   \n",
    "    if loss_append[j]>percentile:   \n",
    "        FP=FP+1\n",
    "    else:\n",
    "        TN=TN+1\n",
    "print (\"TN=\",TN,\"TP=\",TP)\n",
    "print (\"FP=\",FP,\"FN=\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_testing=loss_append\n",
    "normal_testing = np.array_split(normal_testing, len(normal_testing)/32)\n",
    "\n",
    "anomaly_testing=loss_append_ano\n",
    "anomaly_testing = np.array_split(anomaly_testing, len(anomaly_testing)/32)\n",
    "\n",
    "a=np.array(normal_testing).shape\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Testing:\n",
      "\n",
      "Normal Batch1\n",
      "13.3114 17.3876 15.817 14.4219 12.3543 22.3369 20.6648 20.5269\n",
      "21.3785 22.7464 22.2325 16.2996 15.4987 16.8616 15.5455 18.5303\n",
      "25.3443 25.3821 17.8025 11.5602 16.4387 15.2584 15.9959 16.7715\n",
      "14.3889 10.6258 10.6984 13.867 15.4941 13.2474 20.6186 16.1938\n",
      "\n",
      "Normal Batch2\n",
      "14.6357 24.135 21.5189 18.3244 20.1778 18.779 21.0837 29.5901\n",
      "10.3367 8.4233 15.3989 16.8546 17.6925 14.5637 31.7804 33.2833\n",
      "32.9182 40.4152 42.0749 40.0744 34.897 39.109 48.2419 52.5372\n",
      "63.0014 63.8946 71.3912 98.7255 76.1255 83.1536 92.683 107.6207\n",
      "\n",
      "Normal Batch3\n",
      "84.9552 94.3247 125.2037 65.1659 43.6537 55.1431 73.4702 86.0429\n",
      "128.3539 116.5527 149.1821 132.6072 174.2661 186.4011 137.2105 136.6839\n",
      "11.8329 11.0797 10.5122 12.4967 19.6701 17.5804 20.3997 12.468\n",
      "9.2032 7.0911 7.7419 10.6809 10.9042 12.0578 12.8524 11.3462\n",
      "\n",
      "Normal Batch4\n",
      "9.7128 8.9833 12.1193 18.5071 10.8753 8.728 10.6808 9.777\n",
      "9.1351 7.3599 11.2702 12.3639 13.9296 16.8435 20.4167 18.8219\n",
      "10.7058 8.6374 15.3429 9.6943 11.7062 14.2051 9.9441 13.691\n",
      "10.3644 9.2553 8.4907 11.464 15.8648 13.8325 14.9932 14.4916\n",
      "\n",
      "Anomaly Testing:\n",
      "\n",
      "Anomaly Batch1\n",
      "112.2614 89.3293 123.2368 111.7186 189.2 214.5542 102.2892 63.0394\n",
      "94.9869 77.7289 70.8234 52.5199 56.5777 63.6536 42.9297 67.2392\n",
      "503.1303 320.2472 354.2481 414.6165 438.2722 505.069 327.9466 286.1786\n",
      "25.7157 248.2355 10465.3428 10321.1836 8645.9795 8409.1719 9326.7109 10761.7549\n",
      "\n",
      "Anomaly Batch2\n",
      "13227.8584 6137.2871 4474.6812 3114.7385 3279.9946 4472.8267 8107.9795 14104.8682\n",
      "5287.834 3942.7998 334.3032 280.564 297.4358 66.3724 79.2785 78.0419\n",
      "53.66 37.7688 74.6163 63.6924 53.3421 87.2596 60.5847 85.823\n",
      "105.4669 176.8144 67.8948 82.3275 31.9626 75.7112 41.5004 39.7015\n",
      "\n",
      "Anomaly Batch3\n",
      "2665.2939 2374.4434 1040.9232 2491.7925 1065.9443 1685.6021 1476.9156 1715.5786\n",
      "142.2154 138.5142 458.9952 687.2787 862.9761 841.7038 864.0051 152.4262\n",
      "4663.9375 1049.4255 4361.5215 1175.4775 3711.2673 1321.6953 1066.3696 2455.8855\n",
      "2369.97 2386.0391 2215.9375 2466.5295 2387.9531 2315.5498 2330.7031 351.7585\n",
      "\n",
      "Anomaly Batch4\n",
      "356.4008 249.9377 41.1909 137.2821 415.3648 1099.8693 768.2454 91.7479\n",
      "863.985 3574.5791 4601.731 5104.1699 3759.2412 7002.9512 3587.5247 7434.6152\n",
      "4918.9121 327.2947 580.6229 1161.6997 310.9071 239.154 612.0405 575.6317\n",
      "1149.6494 1158.3352 1294.4592 1273.7156 1435.4727 1497.0298 1475.3424 828.9168\n"
     ]
    }
   ],
   "source": [
    "print(\"Normal Testing:\")\n",
    "for b in range(a[0]):\n",
    "    print('\\nNormal Batch{}'.format(b+1))\n",
    "    for i in range(32):\n",
    "        if (i+1)%8!=0:\n",
    "            print(round(normal_testing[b][i],5),end=\" \")\n",
    "        else:\n",
    "            print(round(normal_testing[b][i],5))\n",
    "\n",
    "print(\"\\nAnomaly Testing:\")\n",
    "for c in range(a[0]):\n",
    "    print('\\nAnomaly Batch{}'.format(c+1))\n",
    "    for z in range(32):\n",
    "        if (z+1)%8!=0:\n",
    "            print(round(anomaly_testing[c][z],5),end=\" \")\n",
    "        else:\n",
    "            print(round(anomaly_testing[c][z],5))\n",
    "b=0\n",
    "c=0\n",
    "i=0\n",
    "z=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
